{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "!pip install pyspark"
   ],
   "execution_count":1,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Requirement already satisfied: pyspark in \/opt\/python\/envs\/default_3_11\/lib\/python3.11\/site-packages (3.5.4)\r\n",
      "Requirement already satisfied: py4j==0.10.9.7 in \/opt\/python\/envs\/default_3_11\/lib\/python3.11\/site-packages (from pyspark) (0.10.9.7)\r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"GBQeyUbAga0shzVqzKGGvQ",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#towrzenie lub pobranie sesji Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Analiza zamówień\") \\\n",
    "    .getOrCreate()"
   ],
   "execution_count":2,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25\/05\/12 12:20:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"KVNhkopwB5E0J5G9sv7JY3",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from pyspark.sql.types import StructType,StructField,IntegerType,StringType,DoubleType\n",
    "\n",
    "#tworzenie schematu\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\",IntegerType(),True),\n",
    "    StructField(\"customer_id\",IntegerType(),True),\n",
    "    StructField(\"category\",StringType(),True),\n",
    "    StructField(\"amount\",DoubleType(),True)\n",
    "])\n",
    "\n",
    "#przykładowe dane\n",
    "data = [\n",
    "    (1,101,\"electronics\",299.99),\n",
    "    (2,102,\"books\",16.22),\n",
    "    (3,101,\"books\",22.99),\n",
    "    (4,103,\"electronics\",499.0),\n",
    "    (5,104,\"clothing\",79.90),\n",
    "    (6,102,\"books\",12.97)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ],
   "execution_count":3,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "+--------+-----------+-----------+------+\n",
      "|order_id|customer_id|   category|amount|\n",
      "+--------+-----------+-----------+------+\n",
      "|       1|        101|electronics|299.99|\n",
      "|       2|        102|      books| 16.22|\n",
      "|       3|        101|      books| 22.99|\n",
      "|       4|        103|electronics| 499.0|\n",
      "|       5|        104|   clothing|  79.9|\n",
      "|       6|        102|      books| 12.97|\n",
      "+--------+-----------+-----------+------+\n",
      "\n"
     ],
     "output_type":"stream"
    },
    {
     "name":"stderr",
     "text":[
      "\r[Stage 0:>                                                          (0 + 1) \/ 1]\r\r                                                                                \r"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"ryuMvktEP4bmZll6u8eI8i",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default_3_11",
   "python_version":"3.11",
   "packages":[],
   "report_row_ids":[],
   "report_tabs":[],
   "version":4
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}